[
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.3-s3-secrets-manager/5.3.1-create-secrets-manager/",
	"title": "Create secrets manager",
	"tags": [],
	"description": "",
	"content": " Open the Amazon Secrets manager console In the navigation pane, choose Secrets, then click Store a new secret: In the Create endpoint console: Choose \u0026lsquo;Other type of secret\u0026rsquo; In Key/value pairs, we will have 5 secret names All the next is default. After we create all 5 secrets manager: "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Tran Van Quyet\nPhone Number: 0838972331\nEmail: tranquyetcoder@gmail.com\nUniversity: FPT HCM University\nMajor: Software Engineer\nClass: AWS\nInternship Company: Amazon Web Services Vietnam\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 09/08/2025 to 12/24/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Prepare the environment",
	"tags": [],
	"description": "",
	"content": "Part 1: Networking \u0026amp; Security 1.1 Create VPC Steps:\nGo to VPC Console → Your VPCs → Create VPC Select VPC and more Name: metropolitano Create public/private subnets across at least 2 Availability Zones VPC Endpoints: None (baseline) 1.2 Enable Auto-assign Public IPv4 for Public Subnet Steps:\nVPC → Subnets → Select public subnet → Edit subnet settings Enable Auto-assign Public IPv4 → Save 1.3 Security Groups 1.3.1 Public Web/EC2 Security Group Name: public-web-sg\nInbound rules:\nHTTP/HTTPS from Internet SSH from admin IP only 1.3.2 Private Database Security Group Name: private-db-sg Inbound rules: MS SQL Server (1433) only from public-web-sg Part 2: Database Setup (RDS SQL Server) 2.1 Create DB Subnet Group RDS → Subnet Groups → Create Name: private-db-metropolitano VPC: metropolitano-vpc Subnets: private subnets across 2 AZs 2.2 Create RDS SQL Server Instance Steps:\nRDS → Databases → Create database\nEngine: Microsoft SQL Server Template: Dev/Test Credentials: Self-managed Public access: No Security group: private-db-sg Part 3: Compute – EC2 Application Server Steps:\nGo to EC2 → Instances → Launch instance 2. Name: metropolitano-version-1\n3. AMI: Amazon Linux\n4. Instance type: t3.medium\n5. Key pair: myKey.pm\n6. Network:\nVPC: metropolitano-vpc Subnet: Public subnet Security Group: public-web-sg 7. Wait until instance status = 3/3 checks passed Part 4: Storage – S3 Bucket 4.1 Create S3 Bucket Go to S3 → Buckets → Create bucket\nName: metropolitano-2025 Object Ownership: ACLs disabled (recommended) Block Public Access: Disable Block all public access Click Create bucket Upload the dist folder from frontend Part 5: CloudFront Steps:\nCloudFront Console → Distributions → Create distribution Plan: Free tier Name: Metropolitano Origin type: Amazon S3 Origin: metropolitano-2025 Origin path: /dist Cache settings: Viewer protocol policy: Redirect HTTP to HTTPS Allowed HTTP methods: GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE Wait 3–5 minutes for deployment.\n![Create cloudfront](/images/5-Workshop/5.4-S3-onprem/image_19.png)\r![Websites](/images/5-Workshop/5.4-S3-onprem/image_20.png)\rPart 6: Kinesis – Event Stream Steps:\nConsole → Kinesis → Create Data Stream 2. Name: metropolitano-stream\n3. Shards: Select based on expected data volume\n4. Producers (EC2) will send data; Consumers will process data Part 7: EventBridge – Event Automation Steps:\nConsole → EventBridge → Create Rule Name: metropolitano-event-rule Event source: AWS services (CloudWatch Alarm, S3 Object Created) Target: SQS, SNS Part 8: SQS – Message Queue Steps:\nConsole → SQS → Create Queue Name: metropolitano-queue Queue type: Standard or FIFO Part 9: SNS – Notification Service Steps:\nConsole → SNS → Create Topic Name: metropolitano-alerts Add subscriptions: Email, SMS Part 10: CloudWatch – Monitoring \u0026amp; Alerts Steps:\nConsole → CloudWatch → Create Alarm Metrics: EC2 CPU utilization RDS instance status Kinesis throughput Actions: Send notification via SNS when threshold is exceeded Part 11: Analytics \u0026amp; Visualization Steps:\nConsole → QuickSight → Sign up / Create account Dataset sources: RDS, S3, or Athena Create Analysis → Build dashboards \u0026amp; visual reports "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/3-blogstranslated/3.2-blog2/",
	"title": "Validate Recovery Readiness with AWS Backup Restore Testing",
	"tags": [],
	"description": "",
	"content": "\rCore idea: Many organizations back up critical workloads but don’t regularly confirm those backups can be restored within required recovery targets. This creates risk for disaster recovery (DR), compliance, and cyber resilience.\nAWS Backup restore testing: A capability that automates backup validation by running restore tests in controlled environments and producing evidence/reporting—turning a manual, error-prone process into a repeatable workflow.\nWhy Restore Testing Matters Operational risk: A backup that cannot restore (or restores too slowly) can cause unexpected downtime during real incidents.\nBusiness continuity: Regular validation builds confidence that recovery plans work when needed.\nCompliance \u0026amp; regulation: Many frameworks and regulators require evidence that recovery processes are tested and effective.\nCyber resilience: Ransomware and related threats may target backups; restore validation helps confirm backups remain usable and intact.\nKey Concepts (Keyword Terminology) Data resilience: The ability to maintain and recover data and services through outages or attacks.\nDisaster recovery (DR): Processes and systems used to restore services after disruption.\nRTO (Recovery Time Objective): The maximum acceptable time to restore a service after an incident.\nRPO (Recovery Point Objective): The maximum acceptable data loss measured in time (how far back you can recover).\nRestore testing: Running structured restore operations from backups to verify recoverability, timing (RTO), and integrity.\nIsolated environment (sandbox): A testing space separated from production to reduce operational risk during validation.\nThree Reasons to Adopt AWS Backup Restore Testing 1) Meet Internal DR Goals with Consistent Recovery Validation Problem: DR strategies often create backups but do not continuously validate that recovery targets are met.\nValue delivered:\nSchedule restore validation as part of routine DR drills. Verify RTO/RPO consistently across workloads. Test restores in isolated environments to reduce production risk. Generate detailed reports to support transparency and readiness. Supported workload examples: Common AWS services such as block storage, databases, and object storage can be included in restore validation workflows (depending on configured restore testing support and policies).\n2) Achieve Regulatory Compliance with Documented Evidence Compliance pressure: Organizations—especially in regulated sectors—must demonstrate recovery readiness through tested and documented processes.\nCommon regulation layers:\nGlobal frameworks: Baseline resilience/security expectations that include recovery validation. Regional regulations: Additional resilience requirements based on region (e.g., financial sector mandates). National requirements: Country-specific rules requiring documented testing frequency and proof. How restore testing helps:\nConsistent testing aligned to compliance expectations. Audit logs and evidence for reviewers. Customizable test frequency to match regulatory schedules. Broad support across workload types to reduce compliance gaps. 3) Safeguard Backup Integrity Against Cyber Threats Threat landscape: Attacks may attempt to disrupt recovery by targeting backups. Validation ensures backups are restorable and not corrupted.\nBenefits:\nRoutine integrity checks to detect corruption/tampering. Recovery simulations that confirm procedures work under pressure. Security integrations (for example vault protection and key management) to strengthen tamper resistance. Optional partner integrations (e.g., advanced threat detection during testing) where applicable. Distributed Reference Architecture (Restore Testing) Design goal: Validate recovery readiness without affecting production, while improving security boundaries.\nAccounts separation (high level):\nWorkload account: Hosts production workloads and generates recovery points (backups). Vault account: Stores recovery points in a protected vault design (including logically air-gapped patterns where configured). Forensics account: Performs restore testing using shared recovery points, runs validations, and produces reports. Key outcomes:\nIsolation: Restore tests occur outside production environments. Security: Backup storage and access can be tightly controlled (vault protections, key management, controlled sharing). Evidence: Compliance reports can be produced (for example via AWS Backup Audit Manager reporting patterns). Practical Workflow (High-Level) Step 1 — Define test plan: Select workloads, recovery points, frequency, and validation checks (including RTO/RPO expectations where relevant).\nStep 2 — Execute restores in isolation: Run restore testing in a sandbox/forensics environment.\nStep 3 — Validate outcomes: Confirm:\nRestore completes successfully Recovery time aligns with targets (RTO) Data/app integrity checks pass (where configured) Step 4 — Produce evidence: Generate logs and reports that can be used for audits and internal DR governance.\nThings to Know (Operational Notes) Repeatability: Automation reduces human error and ensures tests run consistently.\nIsolation-first: Restores should be validated in environments designed not to impact production.\nEvidence matters: Logs/reports are as important as successful restores for audits and governance.\nSecurity posture: Strong vault controls and key management increase resistance against tampering and improve confidence in recovery.\nConclusion Bottom line: Backups that are not tested weaken confidence in recoverability and increase risk during outages or cyber events. AWS Backup restore testing automates restore validation, supports recurring DR drills, and helps generate compliance evidence—moving teams from hoping backups work to knowing recovery is achievable.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/3-blogstranslated/3.1-blog1/",
	"title": "Enhanced Network Security Control: Flow Management with AWS Network Firewall",
	"tags": [],
	"description": "",
	"content": "\rAWS Network Firewall: A managed, stateful firewall and IDS/IPS service that enforces security rules for fine-grained control of VPC network traffic.\nProblem context: Once a flow is allowed, that decision can remain in effect for the lifetime of the flow. When rules are updated (e.g., broad → strict), existing long-running flows may continue under the old decision unless action is taken.\nNew capabilities introduced:\nFlow capture: Point-in-time visibility into active flows for monitoring and troubleshooting. Flow flush: Selective termination/removal of flow state (specific flows or all flows) to re-apply policy or isolate suspicious traffic. Access methods: Available through the AWS Management Console and the AWS Network Firewall API.\nKeyword Terminology Active flow: A tracked network connection identified by a 5-tuple (source IP, destination IP, source port, destination port, and protocol) that is not in CLOSED state (e.g., TCP NEW or ESTABLISHED).\nFlow filter: A set of parameters to match active flows using one or more criteria (source/destination IP, ports, protocol). One filter can match multiple flows.\nFlow capture: A firewall operation that generates a point-in-time snapshot of active flows based on filter(s). Used for visibility, security analysis, and validation before flushing.\nFlow flush: A firewall operation that removes selected active flows from the flow table based on filter(s). After flushing, subsequent packets are treated as midstream and re-evaluated against the stream exception policy.\nWorkflow Overview (Capture/Flush) Inspection engine: AWS Network Firewall uses Suricata for stateful inspection and maintains flow state in a flow table.\nCommon flush scenarios:\nFull flush: Clear all active flows (maintenance/troubleshooting). Selective flush: Clear targeted flows (policy updates, suspicious traffic) by IP/port/protocol. Operating modes:\nCapture → Flush: Capture flows first, review results, then flush matched flows. Direct flush: Flush immediately using specified filters. Tracking: Operation status and details can be monitored in Firewall operation history.\nConsole Navigation Step 1: Open Amazon VPC console → Network Firewall → Firewalls\nStep 2: Select a firewall\nStep 3: In Firewall operations, use:\nConfigure flow capture\nConfigure flow flush\nFlow Capture Goal (example): Identify active flows from 10.0.1.0/24 → 10.0.2.0/24 on TCP port 80, then flush them.\nNetwork setup: Traffic between the two subnets is routed through AWS Network Firewall for inspection.\nStart capture via console Action: Select Configure flow capture (from Figure 1).\nAvailability Zone: Select the AZ (required per operation).\nRequired fields: Provide at least one: Source address or Destination address.\nOptional fields:\nMinimum age of flow Source port Destination port Protocol (ICMP, TCP, UDP, IPv6-ICMP, SCTP) Filters: Click Add filter (up to 20 filters; full or partial 5-tuple).\nExecution: Click Start capture.\nPerformance note: More specific filters usually result in faster operation times.\nCapture results Output: The operation displays flows captured by the filter(s).\nFlow Flush Scope: Flush flows based on full or partial 5-tuple filters.\nOption 1: Capture then flush Action: From capture results (Figure 4), select Configure flow flush to reuse the same filters.\nExecution: Click Start flush.\nOption 2: Direct flush Action: From Firewall operations (Figure 1), select Configure flow flush.\nFilter properties: Configure as in capture (same filter fields).\nExecution: Click Start flush.\nOutput: After completion, flushed flows are shown.\nVerification \u0026amp; Logging Reconnect behavior: After flows are flushed, clients typically attempt to reconnect. These retries appear as new flows in subsequent captures.\nNoise control: Use Minimum age to avoid clutter from very recent retry flows.\nFlow logs (stateful engine): If flow logs are enabled, log entries for flushed flows show the field reason = flushed and include the last state before flushing.\n{ \u0026#34;reason\u0026#34;: \u0026#34;flushed\u0026#34;, \u0026#34;last_state\u0026#34;: \u0026#34;ESTABLISHED\u0026#34; } Firewall Operation History Retention: Shows capture/flush operations from the past 12 hours per firewall per AZ.\nPurge: Operations older than 12 hours are automatically removed.\nDetail view: Click an operation ID to view capture/flush details.\nThings to Know (Operational Notes) Concurrency rule: One operation (either flow capture or flow flush) at a time per AZ per firewall.\nMulti-AZ: If firewall endpoints are deployed in multiple AZs, operations can run simultaneously across AZs.\nMinimum age: Helps identify/flush long-running flows (e.g., 300 seconds includes flows active for 5+ minutes).\nStream exception policy: After a flush, packets are evaluated using the firewall policy’s stream exception policy (often recommended: reject).\nDistributed execution: Capture/flush may vary slightly across firewall hosts because operations roll across distributed infrastructure.\nIPv4/IPv6 support: These features support both IPv4 and IPv6 flows.\nAuditing: AWS CloudTrail records flow capture and flush operations as Management events.\nCost: No additional cost; enabled by default.\nConclusion Summary: Flow capture provides point-in-time visibility into active network flows, while flow flush enables selective removal of flow state to re-apply updated security policy or isolate suspicious connections. Together, they improve monitoring, troubleshooting, incident response, and consistent policy enforcement across active connections.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/3-blogstranslated/3.3-blog3/",
	"title": "AWS showcases innovation in media and entertainment with cloud and generative AI at NAB 2025",
	"tags": [],
	"description": "",
	"content": "\rEvent context: Thousands of media and entertainment (M\u0026amp;E) professionals gather at NAB Show 2025 in Las Vegas (April 5–9, 2025). AWS highlights how cloud and generative AI are shaping the future of the industry, from live cloud production to interactive viewer experiences.\nMain focus areas:\nGenerative AI on AWS (including Amazon Nova, Amazon Bedrock, and Amazon Q) Live cloud production using AWS Media Services Audience engagement (D2C + second-screen + interactivity) Monetization innovation (new ad formats and AI-assisted workflows) Games and streaming (including Amazon GameLift Streams) Highlights at NAB 2025 1) Live eSport Racing Challenge (West Hall Lobby) What it is: A live eSport Racing Challenge with four professional-grade racing simulators.\nHow AWS uses it: Event content is reused across the AWS booth workflows, including:\nLive race feed and race data/analytics Post-race interviews conducted by Amazon Nova Cloud-powered sports broadcast workflows enhanced by generative AI Partners mentioned: Presented by AWS and NVIDIA; produced by Tagboard.\nBroadcast note: Sinclair uses AWS for ATSC 3.0 emission of a 4K feed with Advanced HDR for broadcast to a local Las Vegas TV channel.\n2) AWS Booth (W1701): What attendees can explore Live cloud production in action\nA production control room demo showing professional live cloud production workflows Service/partner integration examples New NDI outputs in AWS Elemental MediaConnect to simplify connecting on-prem sources (like cameras) to cloud production AR-enhanced experiences powered by Epic Games’ Unreal Engine Engage audiences in new ways\nBlend direct-to-consumer (D2C) and second-screen applications Integrate social media feeds, live polls, and multi-angle viewing Gamification features that reward participation Demonstrations including volumetric video capture and display Discover new monetization opportunities\nUse data + AI assistant workflows for ad campaign management Contextual ad break demos New ad unit formats such as: Shoppable Video Virtual Product Placement Uncover innovative audio solutions\nPodcast/radio/audio-centric video workflows Live podcast recording using partner Riverside.FM All-day automated radio broadcast with pre-programmed content Podcast localization supported by AWS Elemental Media Services and Amazon CloudFront Connect with experts at the Builder Zone\nArchitecture guidance from AWS experts for M\u0026amp;E use cases AWS for Games demos, including Amazon GameLift Streams (game streaming capability) Explore Amazon Nova (AI Innovation Pavilion) Where: NAB Show AI Innovation Pavilion (West Hall).\nWhat’s showcased: Amazon Nova foundation models and multimodal AI (image, video, speech).\nHands-on experiences:\nUse generative AI to design a real-time racetrack and see it come to life Try Amazon Nova sticker studio to create and print personalized stickers Build with Bedrock and Amazon Q\nLearn to build and scale generative AI apps with Amazon Bedrock See how Amazon Q can support work with customizable AI assistant capabilities Sessions and Agenda Highlights NAB Main Stage session Session: How to Build Entertainment Breakthroughs Using Generative AI and the Cloud\nTime: Sunday, April 6, 2025 | 3:30 PM – 4:30 PM | W4543\nTheme: How generative AI, live cloud production, and interactive technologies are changing entertainment and viewer engagement.\nNAB Sport Summit sessions Beyond Broadcast: The Role of AI, Data Analytics and Personalization\nTuesday, April 8, 2025 | 10:30 AM – 11:15 AM | W224–W225 Closer to the Action: How IMAX \u0026amp; AWS Are Elevating Live Sports Streaming\nTuesday, April 8, 2025 | 1:15 PM – 1:45 PM | W224–W225 AWS Theater (West Hall, W1343) A schedule of 26 sessions from customers and partners across cloud production, AI in media, games, monetization, and more Sessions run all week and do not require advanced registration Takeaways What AWS is demonstrating at NAB 2025: End-to-end M\u0026amp;E workflows powered by cloud and generative AI—covering production, engagement, monetization, audio, and games—supported by AWS services and partner solutions.\nConclusion Summary: AWS’s NAB 2025 presence focuses on practical, hands-on demonstrations that combine cloud media workflows with generative AI (Amazon Nova, Bedrock, Amazon Q) to enable modern live production, interactive viewer experiences, new monetization models, and scalable M\u0026amp;E innovation.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Summary Report: “Gen AI and Data Track – AWS Summit” Event Objectives Present the roadmap and strategy for applying Generative AI (GenAI) on AWS Guide participants on building a unified data platform for analytics and AI Introduce the AI-driven software development lifecycle (AI-DLC) Discuss comprehensive security practices for GenAI applications Explore the role of AI Agents in boosting organizational productivity Speakers Jun Kai Loke – AI/ML Specialist SA, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Key Highlights Building a Unified Data Platform on AWS for AI and Analytics How to design a scalable, unified data platform to support AI and analytics Main components: Data collection from multiple sources Cost-optimized data storage Data processing using AWS Glue, EMR, and Redshift Data governance and access management The goal is to help organizations manage data efficiently for AI projects GenAI Roadmap and Vision on AWS Overview of AWS’s vision and emerging trends in GenAI Key services: Amazon Bedrock – deploy GenAI without managing infrastructure Amazon Q – an integrated AI assistant for enterprises and developers Strategy: start small, expand gradually, and align with business objectives AI-Driven Software Development Lifecycle (AI-DLC) AI-DLC is a new approach that places AI at the core of the entire software development lifecycle AI acts not just as a tool but as a development teammate Benefits: Faster development Higher software quality Greater creativity AI automates tasks such as documentation, test case generation, and code improvement suggestions Securing GenAI Applications on AWS Multi-layered security approach: Infrastructure: encryption and access control AI models: access management and input/output control Applications: user data protection and incident detection Tools and techniques: “Zero-trust” architecture Fine-grained access control Continuous monitoring and auditing AI Agents – Enhancing Productivity Introduction to AI Agents – intelligent assistants capable of learning and handling complex tasks Difference from traditional automation: AI Agents can adapt and autonomously execute actions Applications: customer support, logistics optimization, and real-time analytics Key Takeaways Data Strategy A unified data platform is essential for enabling AI initiatives Data governance is as critical as storage and processing GenAI Roadmap No fixed roadmap – organizations should experiment and expand gradually Amazon Bedrock and Amazon Q are key tools for easier GenAI adoption AI-DLC AI serves as a co-developer, enhancing both speed and software quality Security GenAI security must be multi-layered and follow ethical principles AI Agents AI Agents will soon act as “digital employees” in modern enterprises Organizations should start preparing integration strategies early Application to Work Build a data platform on AWS for AI and analytics projects Experiment with Amazon Bedrock to develop internal GenAI solutions Use Amazon Q Developer to support the software development lifecycle Implement AI-DLC to improve processes such as test case writing and code review Consider integrating AI Agents into business workflows to boost productivity Event Experience Attending the Gen AI and Data track at AWS Summit provided comprehensive insights into AI strategies, especially GenAI in modern enterprises. Learned directly from AWS experts about real-world implementations and best practices Gained exposure to trends such as AI Agents and AI-DLC transforming software development The event inspired me to leverage AI, GenAI, and automation to enhance productivity Lessons learned GenAI is not just technology—it’s a foundation for business process transformation A secure and unified data platform is vital for effective GenAI deployment AI Agents will become digital workforce members, requiring early preparation AI security and ethics must always be prioritized Some event photos "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Summary Report: “BUILDING AGENTIC AI – Context Optimization with Amazon Bedrock” Event Objectives Provide a structured journey through Agentic AI, from high-level architecture to hands-on implementation Introduce core concepts of building autonomous agents using Amazon Bedrock Share real-world use cases for agentic workflows on AWS Present approaches for agentic orchestration and context optimization (L300-level session) Enable practical learning through a hands-on workshop and expert networking opportunities Speakers Nguyen Gia Hung – Head of Solutions Architect Kien Nguyen – Solutions Architect Viet Pham – Founder \u0026amp; CEO Thang Ton – Co-Founder \u0026amp; COO Henry Bui – Head of Engineering Kha Van – Community Leader Key Highlights Event overview \u0026amp; logistics Date: Dec 5, 2025 Location: 26th Floor, Bitexco Financial Tower, Ho Chi Minh City, Vietnam Theme/Tagline: Build autonomous AI agents with Amazon Bedrock through hands-on techniques and real-world use cases AWS Bedrock Agent Core Introduced foundational building blocks for agentic systems on Bedrock: Selecting the right foundation model Tool / function integration to enable action-taking Guardrails and constraints for safety and reliability Tracing and evaluation concepts for production readiness [Use Case] Building Agentic Workflow on AWS Demonstrated how agentic workflows can be applied to practical business/technical scenarios: Multi-step task execution rather than single-turn Q\u0026amp;A Retrieval + reasoning + action loops Human-in-the-loop checkpoints for high-impact operations CloudThinker Agentic Orchestration \u0026amp; Context Optimization (L300) Explained why context quality heavily impacts accuracy, latency, and cost Practical context optimization approaches: Keep context minimal-but-sufficient to reduce noise and hallucinations Separate short-term context vs long-term memory/knowledge Use metadata filtering (scope, recency, relevance) to improve retrieval Apply policies to context (allowlists, redaction, access control) CloudThinker Hack: Hands-on Workshop Guided participants through building an agentic flow: Define objective → design steps → integrate tools → test and iterate Focused on debugging and improving agent behavior: Inspect prompts and tool calls Validate retrieval results and reduce context bloat Add constraints and safety checks Networking \u0026amp; expert discussions Connected with experts and peers to discuss: Deployment constraints (security, governance, cost control) Observability (logging, tracing) and evaluation strategies Integration into real engineering workflows Key Takeaways Agentic AI mindset Agentic AI is more than a chatbot: it requires orchestration, tool usage, memory, and guardrails Context is a critical lever that determines output quality and operational cost Technical approach Separate responsibilities clearly: Planner/orchestrator vs tools/actions vs memory/retrieval vs guardrails Context optimization best practices: Reduce irrelevant context to lower hallucination risk Improve retrieval quality using filters and structure Add traceability for debugging and auditability Responsible deployment Prefer human-in-the-loop for risky operations (ops, security, deployments) Define success metrics (accuracy, latency, cost) and evaluate continuously Application to Work Prototype an internal agent to support: Incident triage, runbook guidance, log summarization Retrieval-based Q\u0026amp;A over internal documentation Apply context optimization: Tighten retrieval scope and reduce prompt bloat Use structured memory and validation checkpoints Improve governance: Add guardrails for tool execution Implement approval flows for critical actions Enable logging/tracing for compliance and troubleshooting Event Experience The event provided a practical end-to-end view of building agentic systems, connecting architecture concepts with implementation details. The L300 session clarified how context optimization directly improves reliability and cost efficiency. The hands-on workshop reinforced best practices for designing, testing, and debugging agentic workflows. Networking sessions helped translate concepts into real-world constraints and adoption strategies. Lessons learned Context quality is as important as model choice for real agent performance Agents must be treated like production systems: safe tool usage, auditing, and evaluation are essential Human-in-the-loop remains critical for high-impact autonomous actions Hands-on iteration (trace → diagnose → refine) is the fastest way to improve agent behavior Some event photos "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Workshop overview Here is a proposed overview of how AWS services are used to set up the Metropolitano system, ensuring the criteria of “high availability - secure - scalable”: Overview of Metropolitano System Architecture on AWS\nThe system is designed to manage, monitor and coordinate urban railway operations, using a range of AWS services for each functional layer:\nLayer AWS Services Role on the Metropolitano system Network \u0026amp; Security Route 53 Manage DNS, route user (operator, management) traffic to applications efficiently and reliably. Network \u0026amp; Security CloudFront Content delivery network (CDN), which helps deliver static content (user interface, reports) with low latency and enhanced security. Network \u0026amp; Security WAF (Web Application Firewall) Protect web applications from common network attacks, filtering malicious traffic before it reaches the application server. Network \u0026amp; Security Secrets Manager Securely manage, rotate, and control access to sensitive information such as database (RDS) passwords, API keys, and other credentials. Helps strengthen application security and minimize the risk of information leakage. Data storage \u0026amp; Application S3 (Simple Storage Service) Store all unstructured and rarely accessed data, such as logs, backups, and project documents Data storage \u0026amp; Application EC2 (Elastic Compute Cloud) Provides compute resources to run back-end applications, orchestration services, and user interfaces. Can be used in Auto Scaling Groups to ensure high availability. Data storage \u0026amp; Application RDS (Relational Database Service) - MSSQL Provides a fully managed relational database running on the Microsoft SQL Server platform. Used to store structured, mission-critical business data (route information, schedules, equipment status). Collect \u0026amp; process Kinesis Build event-driven architectures, automate workflows by connecting different AWS services when events occur (e.g., when data reaches an alert threshold) Collect \u0026amp; process EventBridge Build event-driven architectures, automate workflows by connecting different AWS services when events occur (e.g., when data reaches an alert threshold) Collect \u0026amp; process SQS (Simple Queue Service) Message queues to decouple system components, handle asynchronous tasks (e.g., sending mass notifications, handling dispatch commands). Collect \u0026amp; process SNS (Simple Notification Service) Push notification service for important events, used to send alerts to other systems or operators via email/SMS. Collect \u0026amp; process CloudWatch Monitor resources and applications, collect logs, and set up alarms to ensure system stability and detect problems early. Analyze \u0026amp; Visualization Quicksight Business intelligence (BI) services to visualize data from RDS and Kinesis (after it has been processed), helping management monitor system status in real-time and make decisions. Automation develop CodePipeline Continuous Integration and Delivery (CI/CD) services to automate the entire process of building, testing, and deploying application source code. Automation develop CodeBuild The service builds source code, runs automated tests, and generates deployment-ready packages. Automation develop CodeDeploy The service automates the deployment of source code to EC2 instances or other environments, ensuring smooth, uninterrupted updates. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 1 Objectives: Connect and get acquainted with members of First Cloud Journey (FCJ). Understand foundational AWS concepts and core service groups (Compute, Storage, Networking, Database, \u0026hellip;). Get familiar with the AWS Management Console and basic navigation/operations via the web interface. Install, configure, and practice basic operations using AWS CLI. Start learning and practicing with Amazon EC2 (launching instances, SSH access, EBS volumes, Elastic IP). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 09/05/2025 09/05/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database 09/08/2025 09/08/2025 https://000001.awsstudygroup.com/ 4 - Create an AWS Free Tier account - Enable MFA for root user - Create Admin Group \u0026amp; Admin User (avoid using root user daily) 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/1-create-new-aws-account/ https://000001.awsstudygroup.com/2-mfa-setup-for-aws-user-root/1-virtual-mfa-device/ https://000001.awsstudygroup.com/3-create-admin-user-and-group/ 5 - Verify new AWS account and authentication readiness (Support/verification) - Explore \u0026amp; configure AWS Management Console (default region, search, favorites, widgets) 09/10/2025 09/10/2025 https://000001.awsstudygroup.com/4-verify-new-account/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.1-config-default-region/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.2-search-with-the-aws-management-console/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.3-add-and-remove-favorites/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.4create-and-use-dashboard-widgets/ 6 - Learn EC2 basics: instance types, AMI, EBS - Practice SSH connection methods - Learn Elastic IP and basic cost awareness 09/11/2025 09/11/2025 https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.2-search-with-the-aws-management-console/ https://000001.awsstudygroup.com/5-explore-and-configure-the-aws-management-console/5.1-config-default-region/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database Successfully created and secured an AWS Free Tier account:\nSet up MFA for root user Created Admin Group \u0026amp; Admin User for daily administration Became familiar with the AWS Management Console:\nConfigured default region, used search effectively, managed favorites, and customized dashboard widgets. Prepared for account support and operational readiness:\nReviewed account verification and support case management process. Started EC2 learning foundation:\nUnderstood key concepts (instance/AMI/EBS/Elastic IP) and basic SSH connectivity approach. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 10 Objectives: Understand Hybrid DNS architecture between on-premises DNS and AWS using Route 53 Resolver. Practice deploying required infrastructure with CloudFormation / Quick Start. Configure Resolver Endpoints + Resolver Rules and validate DNS resolution. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop overview and key concepts: Route 53, Route 53 Resolver - Understand Inbound/Outbound endpoints and Resolver rules 11/03/2025 11/03/2025 https://000010.awsstudygroup.com/ 3 - Generate EC2 key pair for secure access (Windows password decryption) 11/04/2025 11/04/2025 https://000010.awsstudygroup.com/2-prerequiste/2.1-createkeypair/ 4 - Deploy network infrastructure using CloudFormation (AWS Quick Start RDGW) - Review created VPC/Subnets and stack outputs 11/05/2025 11/05/2025 https://000010.awsstudygroup.com/2-prerequiste/2.2-launchcloudformation/ 5 - Configure Security Group (restrict ports, allow only needed access from trusted IP) 11/06/2025 11/06/2025 https://000010.awsstudygroup.com/2-prerequiste/2.3-security/ 6 - Connect to the RDGW instance via RDP - Decrypt Windows administrator password using PEM key 11/07/2025 11/07/2025 https://000010.awsstudygroup.com/3-connecttordgw/ 7 - Deploy AWS Managed Microsoft AD (simulate on-premises DNS) in private subnets; record DNS IP addresses of Directory Service - Create Route 53 Resolver Outbound Endpoint - Create Resolver Rule to forward onprem.example.com to AD DNS IPs - (If included in lab) Create Inbound Endpoint for on-prem → AWS resolution - Test with nslookup / Resolve-DnsName on RDGW - Cleanup: delete endpoints, disassociate \u0026amp; delete rules, remove Directory, delete CloudFormation stack 11/08/2025 11/08/2025 https://000010.awsstudygroup.com/4-setupad/ https://000010.awsstudygroup.com/5-setuphyriddns/ https://000010.awsstudygroup.com/6-cleanup/ Week 10 Achievements: Understood the idea of Hybrid DNS and why organizations integrate existing on-prem DNS with AWS DNS capabilities.\nIdentified the 3 main building blocks of Route 53 Resolver for hybrid DNS:\nOutbound Endpoint (AWS → on-prem DNS) Inbound Endpoint (on-prem DNS → AWS hosted zones / VPC DNS) Resolver Rules (conditional forwarding for specific domains) Successfully deployed foundational infrastructure using CloudFormation / AWS Quick Start, including RDGW for management access.\nDeployed AWS Managed Microsoft AD to simulate an on-premises DNS environment and captured Directory DNS IP addresses for forwarding targets.\nConfigured DNS forwarding using:\nRoute 53 Resolver Outbound Endpoint A Forward rule for onprem.example.com Validated DNS resolution on the Windows host using:\nnslookup onprem.example.com Resolve-DnsName onprem.example.com Completed resource cleanup to avoid unexpected charges by removing Route 53 Resolver resources, Directory Service, and deleting the CloudFormation stack.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 2 Objectives: Learn and practice AWS Identity and Access Management (IAM) with a focus on secure access control. Understand IAM core components: User / Group / Policy / Role and the Least Privilege principle. Build a recommended administration model: Create an Admin Group + Admin User for daily administration instead of using the root user. Create AdminRole and OperatorUser, then practice AssumeRole and Switch Role. Understand the difference between Trust policy (who can assume a role) and Permission policy (what the role can do). Perform cleanup of IAM lab resources to maintain security hygiene. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read IAM overview (concepts: user/group/policy/role) - Take notes on best practices (MFA, root user, least privilege, CloudTrail) 09/12/2025 09/12/2025 https://000002.awsstudygroup.com/1-introduction/ https://000002.awsstudygroup.com/1-introduction/1.1-group-user/ https://000002.awsstudygroup.com/1-introduction/1.2-iam-policy/ 3 - Practice: create IAM Admin Group and attach AdministratorAccess - Create AdminUser and add to Admin Group 09/13/2025 09/13/2025 https://000002.awsstudygroup.com/2-create-admin-user-and-group/2.1-create-admin-group/ 4 - Sign in to AWS using AdminUser via the console sign-in URL - Verify permissions and navigate IAM services 09/14/2025 09/14/2025 https://000002.awsstudygroup.com/2-create-admin-user-and-group/2.1-create-admin-group/ 5 - Practice: create AdminRole (attach AdministratorAccess) - Create OperatorUser (no direct permissions attached) 09/15/2025 09/15/2025 https://000002.awsstudygroup.com/3-aws-role/ 6 - Allow OperatorUser to sts:AssumeRole into AdminRole (inline policy) - Sign in as OperatorUser and Switch Role to AdminRole - Cleanup: delete lab users/groups/roles/policies 09/16/2025 09/16/2025 https://000002.awsstudygroup.com/4-switch-roles/ https://000002.awsstudygroup.com/4-switch-roles/4.2-login-operatoruser/ https://000002.awsstudygroup.com/4-switch-roles/4.3-switchrole/ https://000002.awsstudygroup.com/5-cleanup/ Week 2 Achievements: Understood foundational IAM concepts and security best practices:\nIAM Users, Groups, Policies, Roles Difference between Permission policy and Trust policy Applied the Least Privilege principle and avoided using the root user for daily tasks Successfully set up a basic administrative structure:\nCreated an Admin Group and attached AdministratorAccess Created an AdminUser and managed access via group-based permissions Practiced role-based access control (RBAC) using IAM Roles:\nCreated AdminRole with AdministratorAccess Created OperatorUser without direct permissions Configured and validated role assumption:\nAttached an inline policy granting sts:AssumeRole for OperatorUser to assume AdminRole Logged in as OperatorUser and used Switch Role to obtain temporary administrative permissions Completed IAM lab cleanup:\nRemoved created IAM resources (users/groups/roles/policies) to reduce security risk and keep the account tidy "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 3 Objectives: Practice AWS Networking with VPC and Site-to-Site VPN. Understand VPN components (VPG / CGW / 2 tunnels) and routing (Static vs BGP). Learn monitoring + troubleshooting flow (IKE → IPsec → Tunnel → Routing). Perform cleanup to avoid unexpected costs. Get exposure to IaC (CloudFormation / CDK / Terraform). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop: Amazon VPC and AWS Site-to-Site VPN (overview + lab scope) - Understand architecture: VPC ASG (Main office) \u0026amp; VPC ASG VPN (Branch office) and goal (private IP connectivity) 09/17/2025 09/17/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/ 3 - Create Branch environment: ASG VPN VPC 10.11.0.0/16 - Create subnet VPN Public 10.11.1.0/24 (ap-southeast-1a) + enable auto-assign public IPv4 - Create + attach Internet Gateway - Create route table VPN - Public, add 0.0.0.0/0 → IGW, associate with VPN Public subnet 09/18/2025 09/18/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/5.1-createvpnenv/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.1-createvpnenv/5.1.1-createvpnvpc/ 4 - Create security group VPN Public - SG: allow SSH (My IP), ICMP, UDP 500/4500 (IPsec) - Launch Customer Gateway EC2 instance in ASG VPN VPC (public subnet) and verify SSH connection 09/19/2025 09/19/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/5.1-createvpnenv/5.1.2-createec2vpn/ 5 - Create Virtual Private Gateway (VPG) and attach to VPC ASG - Create Customer Gateway (CGW) using public IP of Customer Gateway EC2 - Create Site-to-Site VPN Connection (Static routing, prefix 10.11.0.0/16) - Enable route propagation on related route tables (public + private) 09/20/2025 09/20/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.1-createvpgw/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.2-createcustomergw/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.3-createvpnconnection/ 6 - Download VPN configuration from AWS (OpenSwan/StrongSwan profile) - Configure Customer Gateway software (OpenSwan / Libreswan / StrongSwan depending on OS) - Configure sysctl IP forwarding + IPsec config/secrets for 2 tunnels, start services - Validate private connectivity: ping between Customer Gateway ↔ EC2 Private via private IP 09/21/2025 09/21/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.4-configurecustomergw/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.7-troubleshootingguide/ 7 - Modify AWS VPN tunnel options (verify both tunnels UP) - Enable Tunnel activity log to CloudWatch and review log streams - Practice troubleshooting flow: IKE → IPsec → Tunnel → Routing (check status, logs, routes, firewall rules) - Review alternative configurations: StrongSwan (IKEv2), BGP (dynamic routing), Transit Gateway (optional) 09/22/2025 09/22/2025 https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.5-modifyvpn/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.6-alternativeconfigurations/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.7-troubleshootingguide/ http://000003.awsstudygroup.com/5-vpnsitetosite/5.2-vpnsitetosite/5.2.8-awsofficialtroubleshooting/ https://000003.awsstudygroup.com/5-vpnsitetosite/5.3-vpnsitetosite-optional/ 8 - Cleanup resources to avoid cost: terminate EC2, delete NAT Gateway + release EIP, delete endpoints - Delete VPN resources in order: VPN connection → VPG → CGW → VPCs/related components - Read IaC templates and deployment approaches (CloudFormation / CDK / Terraform) 09/23/2025 09/23/2025 https://000003.awsstudygroup.com/6-cleanup/ https://000003.awsstudygroup.com/7-infrastructureascode/ Week 3 Achievements: Built a branch “on-premises emulator” environment (ASG VPN VPC + public subnet + IGW + routing) to support Site-to-Site VPN lab testing. Successfully set up AWS Site-to-Site VPN core components: Virtual Private Gateway (VPG) attached to VPC ASG Customer Gateway (CGW) using EC2 public IP Site-to-Site VPN connection with 2 tunnels for high availability Static routing configuration and route propagation on VPC route tables Configured the Customer Gateway instance (OpenSwan/Libreswan/StrongSwan) and verified private IP connectivity across the VPN tunnel. Practiced monitoring and troubleshooting with CloudWatch tunnel logs and a structured workflow: IKE → IPsec → Tunnel → Routing checks (status, logs, firewall rules, route tables) Completed cleanup of lab resources (EC2/NAT/EIP/VPN/VPC components) to prevent unexpected charges. Got exposure to Infrastructure as Code (IaC) approaches and sample templates: CloudFormation, AWS CDK, Terraform. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 4 Objectives: Complete Amazon EC2 workshop (000004) end-to-end following the flow: networking prep → launch instances → EC2 basics → deploy app → governance → cleanup. Prepare required infrastructure for the lab: Create VPCs for Linux and Windows workloads. Create Security Groups with least-privilege inbound rules for SSH/RDP/HTTP/HTTPS and application ports. Practice core EC2 operations: Modify instance type Create EBS snapshots Create a custom AMI and launch instances from the AMI Review basic access recovery methods (Windows/Linux) Deploy the sample AWS FCJ User Management (Node.js CRUD) application: On Linux (LAMP + Node.js) On Windows (XAMPP + Node.js) Implement Cost \u0026amp; Usage Governance with IAM (region/service/resource constraints) and perform resource cleanup to avoid charges. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop overview \u0026amp; modules for Amazon EC2 (000004) 09/24/2025 09/24/2025 http://000004.awsstudygroup.com/1-introduce/ 3 - Preparation: create Linux VPC + Windows VPC - Create Linux-SG + Windows-SG (required inbound ports for lab) 09/25/2025 09/25/2025 https://000004.awsstudygroup.com/2-prerequiste/ https://000004.awsstudygroup.com/2-prerequiste/2.1-createvpclinuxinstance/ https://000004.awsstudygroup.com/2-prerequiste/2.2-createvpcwindowsinstance/ https://000004.awsstudygroup.com/2-prerequiste/2.3-createsecuritygrouplinux/ https://000004.awsstudygroup.com/2-prerequiste/2.4-createsecuritygroupwindows/ 4 - Launch Windows Server 2022 instance - Connect to instance via RDP and validate access 09/26/2025 09/26/2025 https://000004.awsstudygroup.com/3-launchwindowsinstance/ https://000004.awsstudygroup.com/3-launchwindowsinstance/3.1-createwindowssintance/ https://000004.awsstudygroup.com/3-launchwindowsinstance/3.2-connectwindowsinstance/ 5 - Launch Amazon Linux instance - Connect via SSH, validate SG rules and networking 09/27/2025 09/27/2025 https://000004.awsstudygroup.com/4-launchlinuxinstance/ https://000004.awsstudygroup.com/4-launchlinuxinstance/4.1-createlinuxinstance/ https://000004.awsstudygroup.com/4-launchlinuxinstance/4.2-connectlinuxinstance/ 6 - EC2 Basic practice: + Modify instance type + Create snapshots + Create custom AMI \u0026amp; launch from AMI + Review access recovery (Windows/Linux) - Deploy app on Linux (LAMP + phpMyAdmin + Node.js CRUD) - Deploy app on Windows (XAMPP + Node.js) - Practice IAM governance policies and perform cleanup (terminate instances, remove AMIs/snapshots/SG/VPC/policies) 09/28/2025 09/30/2025 https://000004.awsstudygroup.com/5-amazonec2basic/ https://000004.awsstudygroup.com/5-amazonec2basic/5.1-changeconfigureec2/ https://000004.awsstudygroup.com/5-amazonec2basic/5.2-createec2snapshot/ https://000004.awsstudygroup.com/5-amazonec2basic/5.3-createcustomami/ https://000004.awsstudygroup.com/5-amazonec2basic/5.4-launchec2ami/ https://000004.awsstudygroup.com/5-amazonec2basic/5.5-keypair-ssm-windows/ https://000004.awsstudygroup.com/5-amazonec2basic/5.6-keypair-user-data-linux/ https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/ https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/6.1-lampserveronec2linux/ https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/6.2-setupnodejsonec2linux/ https://000004.awsstudygroup.com/6-awsfcjmanagement-linux/6.3-awsfcjmanagement/ https://000004.awsstudygroup.com/7-awsfcjmanagement-windows/ https://000004.awsstudygroup.com/7-awsfcjmanagement-windows/7.1-xampponwindows/ https://000004.awsstudygroup.com/7-awsfcjmanagement-windows/7.3-awsfcjmanagement/ https://000004.awsstudygroup.com/8-costusagegovernance/ https://000004.awsstudygroup.com/8-costusagegovernance/8.1-iamretrictregion/ https://000004.awsstudygroup.com/8-costusagegovernance/8.2-iamretrictec2family/ https://000004.awsstudygroup.com/8-costusagegovernance/8.3-iamretrictec2size/ https://000004.awsstudygroup.com/8-costusagegovernance/8.4-iamretrictecebs/ https://000004.awsstudygroup.com/8-costusagegovernance/8.5-iamretricteip/ https://000004.awsstudygroup.com/8-costusagegovernance/8.6-iamretrictetime/ https://000004.awsstudygroup.com/9-cleanup/ Week 4 Achievements: Completed the Amazon EC2 (000004) workshop workflow: Prerequisite → Launch Instances → EC2 Basic → Deploy App → Governance → Cleanup. Set up the lab environment: VPC + subnet/public IP settings for Linux/Windows Security Groups with required ports (SSH/RDP/HTTP/HTTPS/ICMP + application port) Practiced core EC2 skills: Changed instance type Created EBS snapshots Built a custom AMI and launched instances from the AMI Understood basic access recovery approaches (Windows/Linux) Successfully deployed AWS FCJ User Management: Linux: LAMP/MariaDB/phpMyAdmin + Node.js app and CRUD validation Windows: XAMPP + Node.js deployment and functional validation Practiced IAM governance for cost/risk control: restricted region and EC2 constraints (family/size), plus EBS/EIP/time-based control. Performed full cleanup (instances/AMI/snapshots/SG/VPC/IAM policies…) to avoid unexpected charges. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 5 Objectives: Understand core concepts of Amazon RDS (managed relational database, supported engines, storage, HA/DR, security). Build the required network foundation for RDS: Create VPC, subnets across multi-AZ, and DB Subnet Group. Create separate Security Groups for EC2 (app) and RDS (DB) following least privilege. Provision resources and validate connectivity: Launch EC2 (Amazon Linux 2023) as an application host. Create RDS DB instance and collect endpoint/port for application connection. Deploy a sample Node.js application and connect it to RDS. Practice backup/restore using RDS snapshots. Perform full cleanup to avoid ongoing AWS charges. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop introduction \u0026amp; RDS overview (features, engines, backups, security) 10/01/2025 10/01/2025 https://000005.awsstudygroup.com/1-introduce/ 3 - Complete prerequisites: + Create VPC (subnets across at least 2 AZs) + Create EC2 Security Group (HTTP/HTTPS/SSH/app port) + Create RDS Security Group (DB port only from EC2-SG) + Create DB Subnet Group 10/02/2025 10/02/2025 https://000005.awsstudygroup.com/2-prerequiste/ https://000005.awsstudygroup.com/2-prerequiste/1-create-vpc/ https://000005.awsstudygroup.com/2-prerequiste/2-create-ec2-sg/ https://000005.awsstudygroup.com/2-prerequiste/3-create-db-sg/ https://000005.awsstudygroup.com/2-prerequiste/4-create-db-subnetgroup/ 4 - Create EC2 instance (Amazon Linux 2023) - Connect to EC2 via SSH and prepare runtime (Git/Node.js dependencies) 10/03/2025 10/03/2025 https://000005.awsstudygroup.com/3-create-ec2/ 5 - Create Amazon RDS database instance (collect Endpoint/Port/Username) - Verify security group connectivity path (EC2 → RDS) 10/04/2025 10/04/2025 https://000005.awsstudygroup.com/4-create-rds/ 6 - Deploy application: clone repo, install packages, configure .env to point to RDS endpoint - Create database/table and insert test data - Verify app runs and connects to RDS successfully - Perform backup \u0026amp; restore via DB snapshot - Cleanup resources (RDS/EC2/VPC/SG/Subnet group/snapshots/EIP/NAT if created) 10/05/2025 10/06/2025 https://000005.awsstudygroup.com/5-deploy-app/ https://000005.awsstudygroup.com/6-backup/ https://000005.awsstudygroup.com/7-cleanup/ Week 5 Achievements: Understood Amazon RDS fundamentals:\nManaged database service for OLTP workloads, supporting engines such as Aurora, MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server. Key capabilities: automated backups, maintenance windows, scaling options, encryption, and network isolation via VPC. Completed prerequisite network and security configuration:\nBuilt a dedicated VPC and ensured subnets span at least two Availability Zones to support Multi-AZ requirements. Created separate Security Groups: EC2 SG for web/app access and administration (restricted SSH source where applicable). RDS SG allowing DB port access only from EC2 SG (not public IP ranges). Provisioned compute + database successfully:\nLaunched Amazon Linux 2023 EC2 and prepared environment (Git / Node.js). Created an RDS DB instance and confirmed endpoint/port details for application connectivity. Deployed and tested application with RDS:\nCloned the application repository, installed Node.js dependencies, configured .env connection variables. Created database schema (DB + user table) and inserted sample records. Verified the application works end-to-end (CRUD operations) while storing data in RDS. Practiced data protection and recovery:\nReviewed RDS monitoring for backups and executed snapshot restore, noting that restore creates a new DB instance endpoint which may require updating application configuration. Performed full cleanup to control cost:\nDeleted DB instance, snapshots, subnet group (if created), and related network resources; terminated EC2 and removed supporting components to prevent unexpected charges. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 6 Objectives: Understand and deploy FCJ Management with a scalable, highly available architecture using: EC2 Auto Scaling Group (ASG) Application Load Balancer (ALB) Amazon RDS for the database tier Learn how to create an AMI and Launch Template for standardized deployments. Practice and compare scaling approaches (manual, scheduled, dynamic, predictive) using CloudWatch metrics. Clean up all resources properly to avoid unexpected charges. Tasks to be carried out this week: Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review workshop overview and target architecture (ALB + ASG + RDS) - Identify required components and workflow 10/07/2025 10/07/2025 https://000006.awsstudygroup.com/1-introduction/ 3 - Prepare environment: VPC/Subnets across multiple AZs - Configure Security Groups (EC2 + RDS) - Launch baseline EC2 instance (Amazon Linux 2023) 10/08/2025 10/08/2025 https://000006.awsstudygroup.com/2-preparation/ https://000006.awsstudygroup.com/2-preparation/2.1-setup-network/ https://000005.awsstudygroup.com/2-prerequiste/ 4 - Create DB subnet group - Launch Amazon RDS instance (MySQL) - Connect from EC2 to RDS and initialize database + tables + sample data 10/09/2025 10/09/2025 https://000006.awsstudygroup.com/2-preparation/2.3-launch-db-instance/ https://000006.awsstudygroup.com/2-preparation/2.4-add-data-to-db/ 5 - Deploy FCJ Management web server on EC2 (Node.js + PM2) - Configure .env for DB connection - Verify app runs correctly on port 5000 10/10/2025 10/10/2025 https://000006.awsstudygroup.com/2-preparation/2.5-deploy-web-server/ 6 - Create AMI from configured EC2 and build Launch Template - Create Target Group (HTTP:5000) and ALB (internet-facing) - Create Auto Scaling Group and attach ALB Target Group - Prepare/ upload custom metrics for Predictive Scaling in CloudWatch 10/11/2025 10/11/2025 https://000006.awsstudygroup.com/3-create-launch-template/ https://000006.awsstudygroup.com/4-setup-load-balancer/ https://000006.awsstudygroup.com/6-create-auto-scaling-group/ https://000006.awsstudygroup.com/2-preparation/2.6-prepare-metrics-for-predictive-scaling/ 7 - Test scaling solutions (manual / scheduled / dynamic / predictive) - Observe scale-out / scale-in behavior and record results - Clean up resources (ASG, ALB, TG, LT, AMI, EC2, RDS, subnet group, snapshots, etc.) 10/12/2025 10/12/2025 https://000006.awsstudygroup.com/7-test-solutions/7.1-test-manual-scaling-solution/ https://000006.awsstudygroup.com/7-test-solutions/7.2-test-scheduled-scaling-solution/ https://000006.awsstudygroup.com/7-test-solutions/7.3-test-dynamic-scaling-solution/ https://000006.awsstudygroup.com/7-test-solutions/7.4-test-predictive-scaling-solution/ https://000006.awsstudygroup.com/8-cleanup-resources/ Week 6 Achievements: Built understanding of a highly available and scalable AWS architecture:\nALB distributes HTTP traffic across instances. ASG automatically adjusts capacity and improves fault tolerance by multi-AZ placement. RDS provides managed relational database capabilities with network isolation via subnet groups and security groups. Successfully deployed FCJ Management application end-to-end:\nInstalled dependencies (Git, Node.js via nvm, PM2). Configured environment variables for database connectivity. Verified application accessibility through load balancer DNS (port 5000). Standardized instance provisioning for scaling:\nCreated AMI from a configured EC2 instance. Created Launch Template to ensure repeatable instance configuration for the Auto Scaling Group. Implemented Load Balancing and Auto Scaling:\nCreated Target Group and configured ALB listener routing to the app tier. Created ASG attached to the target group with ELB health checks and CloudWatch metrics enabled. Practiced and compared scaling strategies:\nManual scaling: useful for baseline testing but operationally inefficient. Scheduled scaling: suitable for predictable traffic patterns. Dynamic scaling (target tracking): responded to real-time demand using ALB request-based metrics. Predictive scaling: read forecast metrics (noting UTC vs UTC+7 offset) and understood how ASG can pre-launch instances before predicted peaks. Completed full cleanup of workshop resources to avoid ongoing charges, including:\nASG, ALB, target group, launch template, AMI (and related snapshots if applicable), EC2 instances, RDS instance, subnet groups, and associated networking components. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 7 Objectives: Understand AWS cost governance concepts and how AWS Budgets supports cost/usage monitoring. Practice creating multiple budget types (template, cost, usage, RI, Savings Plans) and configuring notifications. Learn how to clean up budgets to avoid unnecessary alerts and keep the account tidy. Tasks to be carried out this week: Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop overview: AWS Budgets concepts, budget types, alerting behavior - Note best practices (multi-threshold alerts, least privilege access, delays in billing updates) 10/13/2025 10/13/2025 https://000007.awsstudygroup.com/ 3 - Create a budget quickly using AWS template (Monthly cost budget) - Review configured thresholds (actual + forecast) 10/14/2025 10/14/2025 https://000007.awsstudygroup.com/0-createtemplate/ 4 - Create a customized Cost Budget - Configure alert recipients and thresholds (e.g., 50/80/90/100%) - Observe budget overview \u0026amp; history screens 10/15/2025 10/15/2025 https://000007.awsstudygroup.com/1-cost-budgets/ 5 - Create a Usage Budget (example: EC2 Running Hours) - Configure actual / forecasted alerts - Understand update latency (billing data refresh cadence) 10/16/2025 10/16/2025 https://000007.awsstudygroup.com/2-usage-budget/ 6 - Create a Reserved Instance (RI) Budget (coverage/utilization monitoring) - Create a Savings Plans Budget (coverage/utilization monitoring) - Note that lab does not require purchasing RIs/Savings Plans 10/17/2025 10/17/2025 https://000007.awsstudygroup.com/3-reservation-budget/ https://000007.awsstudygroup.com/4-saving-plans-budget/ 7 - Review created budgets, alerts, and notification channels - Clean up all lab budgets to prevent ongoing notifications - Verify Budgets list is clean 10/18/2025 10/18/2025 https://000007.awsstudygroup.com/5-clean-up/ Week 7 Achievements: Understood AWS Budgets and how it helps monitor both current and forecasted spend/usage to avoid unexpected costs. Identified and differentiated common AWS budget types: Cost Budget: track spend ($) Usage Budget: track service usage (e.g., EC2 hours) RI Budget: track reserved instance coverage/utilization Savings Plans Budget: track Savings Plans coverage/utilization Successfully created budgets using: Template-based setup (fast setup with default recommended alerts) Customized (advanced) setup for granular control (scope, thresholds, recipients) Configured alerts using multiple thresholds and understood limitations: Billing/usage data updates are not instant, so alerts may lag behind real-time usage. Forecast alerts can trigger multiple times as predictions change. Practiced good governance hygiene: Cleaned up lab budgets after completing exercises to avoid alert fatigue and account clutter. "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 8 Objectives: Understand the fundamentals of Amazon CloudWatch and the role of monitoring/observability on AWS. Practice working with Metrics, Logs, Logs Insights, Metric Filters, Alarms, and Dashboards. Perform resource cleanup after completing the workshop to avoid unexpected charges. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review AWS CloudWatch Workshop overview - Understand the monitoring flow: Metrics ↔ Logs ↔ Alarms ↔ Dashboards 10/20/2025 10/20/2025 https://000008.awsstudygroup.com/1-introduction/ 3 - Follow preparatory steps (resource setup) - Verify created resources and access permissions 10/21/2025 10/21/2025 https://000008.awsstudygroup.com/2-preparatory-steps/ 4 - CloudWatch Metrics: view \u0026amp; compare EC2 metrics (CPUUtilization, EBSWriteBytes, …) - Improve charts (left/right Y-axis, horizontal/vertical annotations) 10/22/2025 10/22/2025 https://000008.awsstudygroup.com/3-cloud-watch-metric/3.1-view-metrics/ 5 - Search expressions: use SEARCH() for faster metric discovery - Math expressions: apply simple calculations and sorting (e.g., SORT(e1, SUM, DEC, 3)) 10/23/2025 10/23/2025 https://000008.awsstudygroup.com/3-cloud-watch-metric/3.2-search-expression/ https://000008.awsstudygroup.com/3-cloud-watch-metric/3.3-math-expression/ 6 - Dynamic labels: auto-generate readable labels using PROP('Dim...') - Format labels like ${PROP('Dim.exe')} - ${PROP('Dim.InstanceId')} - ${PROP('MetricName')} 10/24/2025 10/24/2025 https://000008.awsstudygroup.com/3-cloud-watch-metric/3.4-dynamic-label/ 7 - CloudWatch Logs: explore /ec2/linux/var/log/messages, adjust retention - Logs Insights: generate sample logs and query by ERROR/WARN, save queries - Metric Filter: convert ERROR logs → metric (ec2-logs) - Alarms: create alarm + SNS email notifications - Dashboards (optional): build a dashboard combining metrics + alarms - Cleanup: delete the CloudFormation stack and review remaining resources 10/25/2025 10/26/2025 https://000008.awsstudygroup.com/4-cloud-watch-logs/ https://000008.awsstudygroup.com/4-cloud-watch-logs/4.2-logs-insights/ https://000008.awsstudygroup.com/4-cloud-watch-logs/4.3-metric-filter/ https://000008.awsstudygroup.com/5-cloud-watch-alarm/ https://000008.awsstudygroup.com/6-cloud-watch-dashboard/ https://000008.awsstudygroup.com/7-clean-up-resources/ Week 8 Achievements: Understood Amazon CloudWatch as AWS’s monitoring \u0026amp; observability service for collecting and visualizing metrics/logs, and triggering automated actions via alarms. Practiced analyzing CloudWatch Metrics: Compared CPUUtilization across multiple EC2 instances. Observed the relationship between CPU usage and storage I/O (EBSWriteBytes). Improved chart readability using dual Y-axes and annotations. Learned advanced metric operations: Used SEARCH() to quickly find metrics across namespaces. Used metric math (e.g., SORT(...)) to rank and visualize top metrics. Implemented Dynamic Labels to automatically generate clear metric names when multiple dimensions exist. Worked with CloudWatch Logs \u0026amp; Logs Insights: Explored log groups/streams and configured log retention. Queried logs by keywords (ERROR/WARN), visualized results, and saved reusable queries. Created Metric Filters to convert logs into numeric metrics and configured CloudWatch Alarms: Set threshold-based alarms (e.g., ERROR count exceeding a limit in 1 minute). Integrated SNS email notifications to receive alerts. (Optional) Built a CloudWatch Dashboard to monitor key metrics and alarm states in a single view. Completed resource cleanup by deleting the CloudFormation stack and reviewing remaining monitoring data (logs/metrics retention). "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 9 Objectives: Learn about AWS Support and AWS Support Plans. Know how to access Support Center, create and manage support cases. Understand how to choose the right Severity level for support requests. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read overview of AWS Support service - Understand when AWS Support is needed 10/27/2025 10/27/2025 https://000009.awsstudygroup.com/ 3 - Learn AWS Support Plans: Basic / Developer / Business / Enterprise - Compare benefits between plans 10/28/2025 10/28/2025 https://000009.awsstudygroup.com/1-support-plans/ 4 - Learn types of Support Requests (cases): + Account and Billing support + Service limit increase + Technical support 10/29/2025 10/29/2025 https://000009.awsstudygroup.com/2-access-support/2.1-support-types/ 5 - Learn how to change support plan (e.g., Basic → Developer) 10/30/2025 10/30/2025 https://000009.awsstudygroup.com/2-access-support/2.2-change-support-package/ 6 - Practice (simulation): Create a support request in AWS Support Center - Fill in: Type, Category, Subject, Description, Attachments, Contact method 10/31/2025 10/31/2025 https://000009.awsstudygroup.com/3-manage-cases/3.1-create-request/ 7 - Learn how to select Severity level and response times per plan - Take notes for appropriate severity usage 11/01/2025 11/01/2025 https://000009.awsstudygroup.com/3-manage-cases/3.2-select-severity/ Week 9 Achievements: Understood the purpose of AWS Support and how it helps with account/billing, service limits, and technical issues depending on the support plan.\nIdentified and compared AWS Support Plans:\nBasic: account \u0026amp; billing support, service limit increase, documentation/forums. Developer: best practices guidance, technical support via web/email (business hours). Business: 24/7 technical support, Trusted Advisor, support API, broader IAM user coverage. Enterprise: highest priority support, TAM, event management, architecture guidance. Explained the main types of support cases:\nAccount and Billing support Service limit increase Technical support (not available for Basic plan) Learned the process to change support plan and understood that activation may take a short time after confirmation.\nPracticed creating a support case with proper information:\nClear subject and detailed description Provide evidence (screenshots) when needed Choose the correct contact method (chat/email/phone depending on plan) Understood how to choose Severity appropriately based on impact (general guidance → system impaired → production impaired → production down) and noted the different response times by support plan.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "\rThis worklog summarizes my internship learning journey over 12 weeks in the AWS First Cloud Journey program. Each week includes the objectives, tasks performed, learning resources, and outcomes. I followed the workshops in order, completed hands-on labs (with both Console and AWS CLI where applicable), recorded key notes and screenshots as evidence, and ensured proper resource cleanup after each lab to avoid unexpected charges.\nAcross the 12 weeks, I covered: AWS fundamentals and core services, EC2 and networking basics, database deployment with RDS, high availability and scaling with ALB/ASG, cost governance (Budgets), monitoring and observability (CloudWatch), AWS Support workflows, hybrid DNS with Route 53 Resolver, AWS CLI operations, and identity \u0026amp; multi-account management with IAM Identity Center and Organizations.\nBelow are the weekly entries:\nWeek 1: Getting familiar with AWS and basic AWS services\nWeek 2: Getting to know FCJ team and AWS basics (Console/CLI foundations)\nWeek 3: Building foundational AWS skills and core service exploration\nWeek 4: Amazon EC2 workshop (000004): VPC/SG, launch instances, deploy app, governance \u0026amp; cleanup\nWeek 5: Amazon RDS workshop (000005): VPC/subnet group, EC2→RDS connectivity, deploy app, backup/restore \u0026amp; cleanup\nWeek 6: High Availability \u0026amp; Scaling (000006): ALB + ASG + RDS, launch template/AMI, scaling tests \u0026amp; cleanup\nWeek 7: AWS Budgets (000007): cost/usage/RI/Savings Plans budgets, alerts \u0026amp; cleanup\nWeek 8: Amazon CloudWatch (000008): metrics, logs insights, alarms, dashboards \u0026amp; cleanup\nWeek 9: AWS Support (000009): support plans, support center, case creation \u0026amp; severity selection\nWeek 10: Hybrid DNS (000010): Route 53 Resolver endpoints/rules, Managed AD, validation \u0026amp; cleanup\nWeek 11: AWS CLI (000011): profiles/config, S3/IAM/VPC/EC2 operations, troubleshooting \u0026amp; cleanup\nWeek 12: IAM Identity Center + Organizations (000012): multi-account setup, permission sets, time-based access, APIs \u0026amp; cleanup\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "3.1 AWS account, Region \u0026amp; IAM Region + Choose region to deploy(ap-southeast-1) IAM baseline + Infra/Admin group: Administrator, Prefer to separate by environment (dev/stg/prod). + Stakeholders: ReadOnlyAccess + CI/CD (service roles): CodePipeline, CodeBuild, CodeDeploy + EC2 instance profile rule(run time): Read secrets from Secrets Manager follow prefix(example: metro//*),push log/metrics into CloudWatch, S3/Kinesis/SNS for function Security Notes + Do not give AdministratorAccess for EC2 Role + Using least privilege: policy for ARN resource + prefix + Turn the MFA for importmant IAM Users/roles + Activate the baseline guardrails {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "\rAWS First Cloud AI Journey – Metropolitano Railways Project Team: FPT HCM University\nClient: Metropolitano Railway Systems\nDocument Date: 12/09/2025\nTABLE OF CONTENTS BACKGROUND AND MOTIVATION\n1.1 EXECUTIVE SUMMARY\n1.2 PROJECT SUCCESS CRITERIA\n1.3 ASSUMPTIONS SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM\n2.1 TECHNICAL ARCHITECTURE DIAGRAM\n2.2 TECHNICAL PLAN\n2.3 PROJECT PLAN\n2.4 SECURITY CONSIDERATIONS ACTIVITIES AND DELIVERABLES\n3.1 ACTIVITIES AND DELIVERABLES\n3.2 OUT OF SCOPE\n3.3 PATH TO PRODUCTION EXPECTED AWS COST BREAKDOWN BY SERVICES TEAM RESOURCES \u0026amp; COST ESTIMATES ACCEPTANCE 1. BACKGROUND AND MOTIVATION 1.1 EXECUTIVE SUMMARY Client background:\nRapid urbanization is increasing pressure on public transportation systems. Metropolitano Railway Systems is modernizing operations to improve reliability, passenger experience, and operational efficiency. Current on-premises systems face challenges in scalability, high availability, and real-time data processing.\nBusiness \u0026amp; Technical Objectives:\nEnsure high availability and 24/7 operations for mission-critical rail services. Enable elastic scalability to handle peak passenger loads and seasonal demand. Improve system reliability and disaster recovery capabilities. Support real-time data processing for ticketing and payment transaction monitoring, including payment status tracking and reconciliation. Strengthen security \u0026amp; compliance aligned with public-sector transportation standards. Reduce operational costs through cloud-native automation. Accelerate innovation cycles for digital services such as mobile ticketing and predictive maintenance. Use cases (POC scope):\nDigital ticketing \u0026amp; fare collection (web/app booking, QR/IC card integration). Train scheduling \u0026amp; dispatch management (contextual use case; not the primary focus of this POC). Real-time payment/transaction event analytics through Amazon Kinesis (e.g., payment status updates, settlement events, anomaly detection). BI dashboards for management decision-making using Amazon QuickSight. Incident response and alerting through centralized monitoring and logging. Summary of Professional Services (Project Team):\nDesign an AWS architecture that is secure, scalable, and fault-tolerant based on Amazon EC2 and managed services. Migrate selected workloads from on-premises infrastructure to AWS (POC scope). Implement real-time payment/ticketing event pipelines using Amazon Kinesis, with storage and analytics datasets delivered to Amazon S3. Deploy analytics using QuickSight. Set up CI/CD using CodePipeline, CodeBuild, and CodeDeploy. Provide knowledge transfer/training to ensure operational readiness for the Client’s technical team. 1.2 PROJECT SUCCESS CRITERIA Service Reliability \u0026amp; Availability\nThe deployed system must achieve ≥ 99.9% uptime across all mission-critical services in scope (ticketing, payment monitoring, analytics). Scalability \u0026amp; Performance\nThe platform must automatically scale to handle peak passenger traffic without performance degradation. End-to-end response time for booking and payment APIs must remain under 300 ms during peak load tests (target). Real-Time Data Processing\nReal-time payment and ticketing transaction events must be processed with a latency under 5 seconds using Amazon Kinesis. Data ingestion pipelines must support at least 10,000 events/second with auto-scaling (target). Analytics \u0026amp; Insights Delivery\nManagement dashboards (QuickSight) must provide accurate, refreshed datasets within ≤ 5 minutes of data arrival in S3. CI/CD \u0026amp; Operational Excellence\nAll application deployments must be executed via automated CI/CD pipelines with rollback capability. Cost Efficiency\nAWS cost optimization mechanisms (Auto Scaling, RI/Savings Plans, lifecycle policies) target a reduction of at least 20% compared to on-premises operations. Cost Explorer and Billing Alarms must be configured to prevent overruns. 1.3 ASSUMPTIONS Prerequisites \u0026amp; Dependencies\nThe Client provides timely access to required environments, systems, and personnel. The Client supplies necessary credentials, API documentation, and integration endpoints for on-premises/third-party systems. Existing operational data (ticketing, scheduling, payment transactions) is available and accessible for migration and integration. Third-party vendors (payment gateways, fare systems, transit card systems) offer stable APIs and complete documentation. Required AWS accounts/organizations/billing structures are set up prior to project start. The Client identifies Subject Matter Experts (SMEs) for each domain (operations, IT, ticketing, scheduling). Technical Constraints\nSome legacy systems may remain on-premises, requiring hybrid connectivity via VPN or Direct Connect. Existing applications may have non-cloud-optimized architectures, limiting modernization within the POC scope. Legacy data quality issues may affect migration accuracy and analytics output. Operational networks and payment/ticketing systems must support secure and reliable cloud connectivity. Real-time analytics performance depends on ingestion latency and stability from payment gateways and ticketing transaction sources. Business Constraints\nProject timelines may depend on internal Client approvals/procurement processes. The Client’s organizational readiness and staff availability may impact progress. Budget limitations may restrict scope. Certain regulatory/compliance requirements may limit data residency/retention options. Risks (high-level)\nIntegration risk (legacy undocumented behaviors). Data migration risk (inconsistent/incomplete legacy data). Operational risk (hybrid/on-prem hardware failures). Security risk (misconfigured third-party endpoints). Timeline \u0026amp; dependency risk (vendor approvals, API throughput). 2. SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM 2.1 TECHNICAL ARCHITECTURE DIAGRAM Figure 1. AWS Technical Architecture Diagram – Metropolitano Railways (POC)\nFigure 1 (POC Outcome \u0026amp; Architecture Summary):\nThe POC enables near real-time monitoring and reconciliation of ticketing/payment transactions. Payment status events are streamed into Amazon Kinesis and delivered to Amazon S3 (data lake) for analytics. Amazon QuickSight dashboards provide revenue insights (daily/monthly) and highlight unpaid/incomplete payments for follow-up. User traffic is routed via Route 53 → CloudFront → AWS WAF to the application on Amazon EC2, with transactional data stored in Amazon RDS (private subnet). Amazon CloudWatch supports monitoring and alerting. Asynchronous workflows are decoupled using SNS/SQS (and EventBridge where needed). Source control uses GitLab; CI/CD is implemented using CodePipeline/CodeBuild/CodeDeploy.\nProduction note (recommendations for production readiness):\nEnable Multi-AZ and place workloads in private subnets behind an ALB. Restrict egress using NAT Gateway and/or VPC Endpoints. Enforce TLS (ACM), least-privilege IAM, and store secrets in Secrets Manager/SSM. Enable CloudTrail/Config and strengthen logging (WAF/CloudFront logs). Use blue/green or canary deployments with rollback. 2.2 TECHNICAL PLAN Key activities include:\nInfrastructure provisioning using IaC templates to deploy: Amazon EC2 clusters for application workloads Amazon RDS for database services Amazon S3 for static content and data lake storage Amazon Route 53 for DNS routing Amazon CloudFront and AWS WAF for secure global content delivery Amazon Kinesis for real-time data ingestion Amazon SQS/SNS for asynchronous messaging Amazon EventBridge for event-driven workflows Amazon CloudWatch for logging, monitoring, alarms, and dashboards Amazon QuickSight for analytics and BI reporting This POC does not include AWS Lambda; streaming consumers and asynchronous/background processing are implemented on EC2-based services (or containers) and integrated via SNS/SQS/EventBridge where applicable. Application build and release processes will be automated using CodePipeline, CodeBuild, and CodeDeploy, enabling blue/green or rolling deployments with automated rollback. Configuration items requiring approvals (production DNS changes, WAF rule modifications, RDS parameter adjustments, security group updates) will follow the Client’s Change Management Process (including CAB approvals and tracked deployment records). Critical paths (ticketing workflows, payment integrations, real-time ingestion, analytics refresh flows) will undergo unit, integration, load, and failover testing. Test scenarios, acceptance criteria, and validation procedures are provided in Appendix X. 2.3 PROJECT PLAN Stakeholder Participation:\nClient stakeholders (Operations, IT, Data, Security teams) are required for: Sprint Reviews (demo and feedback) Sprint Retrospectives (continuous improvement) UAT and sign-off sessions Technical design workshops Team Responsibilities (high-level):\nCloud Architect – AWS solution design, security architecture, scalability \u0026amp; HA patterns DevOps Engineer – CI/CD pipelines, IaC, automated deployments Application Engineer – application refactoring and integration Client IT Lead – access provisioning, governance alignment Client Operations Team – process validation, UAT testing Client Security Officer – compliance and security controls review Data Engineer – Kinesis pipelines, SQS/SNS integration, data modeling Analytics/BI Engineer – QuickSight dashboards and dataset automation Communication Cadence:\nDaily: standups with Project Team Weekly: project status updates to Client stakeholders Bi-weekly: sprint review + sprint planning Monthly: steering committee meeting Ad-hoc: incident response, change approvals, design deep-dives Knowledge Transfer:\nAWS architecture overview CI/CD pipeline management Monitoring and incident response using CloudWatch Data pipeline operations (Kinesis → S3 → QuickSight) Infrastructure lifecycle \u0026amp; IaC updates Security and IAM operations 2.4 SECURITY CONSIDERATIONS Access Security\nImplement least-privilege IAM, role-based access control, and best-practice IAM policies. Enable MFA for privileged accounts. Restrict CI/CD access using scoped IAM roles. Apply change approvals for Route 53 DNS, CloudFront updates, and WAF rule modifications. Infrastructure Security\nDeploy Amazon EC2 in private subnets within a Multi-AZ VPC architecture (production target). Use AWS WAF to protect CloudFront distributions and application endpoints against common exploits. Enforce traffic boundaries via Security Groups and NACLs. Run Amazon RDS in Multi-AZ with encrypted storage and automated backups. Use EventBridge for security-trigger automation (e.g., config rule violations), where applicable. Data Security\nEncrypt data at rest in S3, RDS, Kinesis, and SQS using AWS KMS CMKs. Protect data in transit using TLS 1.2+ across all services. Configure S3 lifecycle policies and object versioning for retention compliance. Data lake structure follows separation of raw, processed, curated layers. Detection \u0026amp; Monitoring\nEnable AWS CloudTrail and AWS Config for full API auditing and compliance tracking. CloudWatch collects logs, metrics, application traces, alarms, and dashboards. Deliver WAF logs and CloudFront access logs to S3 for security analytics. Incident Management\nDesign incident response playbooks for system failures, security breaches, data exposure, and pipeline errors. Trigger automated alerts using SNS/EventBridge to the Client’s operations team. Implement disaster recovery procedures for critical EC2 and RDS workloads. Ensure backup snapshots comply with Client-defined retention policies. Route operational alarms to the correct on-call teams for faster MTTR. 3. ACTIVITIES AND DELIVERABLES 3.1 ACTIVITIES AND DELIVERABLES Timeline basis: Internship duration 08/09/2025 – 22/11/2025 (~11 weeks)\nProject Phase Timeline Activities Deliverables / Milestones Total man-day Assessment Week 1–2 (08/09–21/09) Requirements workshops (business/technical/security); current-state analysis; identify integration points (payments, ticketing, analytics); environment readiness validation Assessment report; Architecture blueprint v1; Backlog \u0026amp; sprint plan TBD Setup base infrastructure Week 3–4 (22/09–05/10) VPC/subnets/routing/SGs; IAM baseline; S3 data lake foundation; CloudFront + WAF + Route53; RDS setup; CloudWatch Infrastructure provisioned; IaC templates delivered; Networking \u0026amp; security baseline TBD Setup component 1 Week 5–6 (06/10–19/10) EC2 Auto Scaling setup; deploy application backend; configure CI/CD (CodePipeline/CodeBuild/CodeDeploy); observability dashboards Application deployed; CI/CD pipelines operational; Monitoring dashboard TBD Setup component 2 Week 7–8 (20/10–02/11) Kinesis streaming pipelines; SQS/SNS messaging; ETL to S3 data lake; QuickSight dashboards; EventBridge workflows Data pipeline operational; Event-driven architecture; Revenue dashboards (daily/monthly); Unpaid/incomplete payments report (with alert thresholds) TBD Testing \u0026amp; Go-live (POC) Week 9–10 (03/11–16/11) Unit/integration/load testing; go-live readiness review; (POC) DNS cutover; monitoring \u0026amp; rozllback plans UAT sign-off; Go-live checklist; POC launch TBD Handover Week 11 (17/11–22/11) Final documentation; operations training; knowledge transfer sessions; transition to BAU Runbooks \u0026amp; SOPs; Admin training completion; Final acceptance TBD How to calculate man-day (guideline):\nMan-day = number of people × number of working days actually spent on the phase. Example: 5 people work 3 days on “Assessment” → 5 × 3 = 15 man-days. If you track by hours: 1 man-day ≈ 8 working hours (common convention). Example: total 120 hours → 120 / 8 = 15 man-days. 3.2 OUT OF SCOPE Custom application code development or feature enhancements not listed in the Scope of Work. On-premises infrastructure upgrades, network redesign, or hardware procurement. Performance tuning of third-party vendor systems. Mobile app development or UI/UX redesign outside the scope. Machine Learning model development beyond QuickSight \u0026amp; basic SageMaker patterns. Penetration testing or third-party security audits (unless contracted separately). Post go-live 24/7 operations unless contracted separately. Support for legacy networks or non-cloud-compatible components. Migration of data sources not included in the initial assessment. AWS Lambda–based serverless compute (event consumers/functions) is out of scope for this POC. 3.3 PATH TO PRODUCTION The Proof of Concept (POC) environment will demonstrate selected use cases defined in Section 2.2.\nThe POC environment will not contain all production-grade capabilities.\nKey gaps requiring enhancements before production deployment include:\nFull resilience design (multi-AZ, failover, scaling policies). Complete observability coverage (CloudWatch metrics, distributed tracing, WAF logs). Hardened security baselines (advanced IAM controls, WAF tuning, encryption policies). Comprehensive testing (integration, performance, DR simulation). CI/CD hardening and automated rollback. Production-approved DNS, WAF, and network change processes. Enhanced error handling and exception flows for edge cases. 4. EXPECTED AWS COST BREAKDOWN BY SERVICES Costing considerations (high-level):\nEC2 estimated using a mix of On-Demand + Reserved Instances/Savings Plans (production). Multi-AZ RDS with automated backups. CloudFront cost includes WAF usage (rule groups + request filtering). S3 includes storage tiers (Standard, Intelligent-Tiering) and lifecycle policies. Log storage and metrics in CloudWatch. Kinesis ingest \u0026amp; processing units. Data transfer cost between components. QuickSight Reader \u0026amp; Author licenses. Messaging (SQS, SNS, EventBridge) based on estimated throughput. Route 53 DNS queries + health checks. Assumptions (for accurate pricing):\nDaily ingestion volume: X GB/day via Kinesis. EC2 sizing based on projected user load for ticketing and payment workloads. S3 storage baseline calculated for 12 months retention. Moderate WAF rule usage and CloudFront regional edge charges. SQS/SNS/EventBridge traffic estimated from projected workflow processes. QuickSight usage includes 1 Author and X Readers. 5. TEAM Name Title Description Email / Contact Info Tào Bảo Thành Team Leader Manage the project, configure AWS services, code Backend, write documents, design architecture taobaothanh365@gmail.com Nguyễn Thị Nhã Uyên Member Design the UI and code Frontend uyenntnse183774@fpt.edu.vn Nguyễn Bảo Khánh Member Design the UI and code Frontend baokhanhtcv2005@gmail.com Trần Văn Quyết Member Code Backend quyettvse181574@fpt.edu.vn Nguyễn Văn Cường Member Code Backend cuongnvse183645@fpt.edu.vn Download Proposal Template\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 11 Objectives: Learn and practice using AWS CLI v2 to manage AWS resources efficiently. Understand AWS CLI concepts: credentials, profiles, region, output format, and basic troubleshooting. Use AWS CLI with core services: S3, IAM, VPC, EC2 and perform proper resource cleanup. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Review workshop overview “Getting Started with the AWS CLI” - Understand AWS CLI, supported environments, credentials, profiles, region/output formats 11/10/2025 11/10/2025 https://000011.awsstudygroup.com/1-introduce/ 3 - Install AWS CLI v2 on the computer (Windows/Ubuntu) - Verify installation with aws --version 11/11/2025 11/11/2025 https://000011.awsstudygroup.com/3-installcli/ 4 - Configure CLI using aws configure (Access Key, Secret Key, region, output) - Create and use multiple profiles (--profile) - Check configurations (aws configure list, list-profiles) 11/12/2025 11/12/2025 https://000011.awsstudygroup.com/3-installcli/ 5 - Practice viewing resources via CLI (describe/list commands) and reading outputs (json/text/table) - Practice with Amazon S3: create bucket, list buckets/objects, delete object, remove bucket 11/13/2025 11/13/2025 https://000011.awsstudygroup.com/4-infras/ https://000011.awsstudygroup.com/5-s3/ 6 - Practice with IAM: create group, create user, add user to group; create \u0026amp; delete access key - Practice with VPC: create VPC/subnets; create/attach Internet Gateway; create route table, add route, associate route table 11/14/2025 11/14/2025 https://000011.awsstudygroup.com/7-iam/ https://000011.awsstudygroup.com/8-network/ 7 - Create EC2 instance using AWS CLI: create key pair, security group, allow SSH, run instance, check public IP, SSH connect, terminate instance - Read Troubleshooting notes for common AWS CLI errors and references - Clean up resources in the correct order (SG → Subnet → Route Table → Detach IGW → Delete IGW → Delete VPC) 11/15/2025 11/15/2025 https://000011.awsstudygroup.com/9-ec2/ https://000011.awsstudygroup.com/10-troubleshoot/ https://000011.awsstudygroup.com/11-cleanup/ Week 11 Achievements: Installed and successfully verified AWS CLI v2 on the computer.\nConfigured AWS CLI with:\nAccess Key Secret Key Default Region Output format\nand understood how to work with multiple profiles. Practiced managing AWS resources via CLI and became familiar with commonly used commands for checking resources (describe, list) and reading outputs (json/text/table).\nCompleted hands-on exercises with multiple AWS services using AWS CLI:\nAmazon S3: created bucket, listed resources, deleted objects/bucket. IAM: created group/user, managed group membership, created/deleted access keys. VPC: created VPC \u0026amp; subnets, set up Internet Gateway and routing. EC2: created key pair \u0026amp; security group, launched an instance, connected via SSH, and terminated the instance. Learned basic troubleshooting practices and performed resource cleanup correctly to avoid dependency errors and minimize unexpected charges.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "\rWeek 12 Objectives: Understand AWS IAM Identity Center (AWS SSO) and how it supports centralized identity \u0026amp; access management. Practice setting up a basic multi-account structure using AWS Organizations and role switching. Apply security concepts: least privilege, time-based access control, and customer managed policies in permission sets. Get exposure to automation via IAM Identity Center Identity Store APIs (Python/Boto3). Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Read workshop overview and scenario - Identify prerequisites, recommended region, expected cost notes 11/17/2025 11/17/2025 https://000012.awsstudygroup.com/1-prerequisite/ 3 - Create member accounts in AWS Organizations (Security/Shared Services/Logging/Application) - Create and organize Organizational Units (OUs) 11/18/2025 11/18/2025 https://000012.awsstudygroup.com/1-prerequisite/ 4 - Invite an existing AWS account into AWS Organizations (if needed) - Practice Switch Role to member accounts (OrganizationAccountAccessRole) - Understand least-privilege approach for assume-role permissions 11/19/2025 11/19/2025 https://000012.awsstudygroup.com/1-prerequisite/4-switch-role/ 5 - Configure AWS CLI access using IAM Identity Center (SSO) - Compare manual credential refresh vs aws configure sso automatic refresh (OIDC device code) 11/20/2025 11/20/2025 https://000012.awsstudygroup.com/2-aws-cli-access/ 6 - Implement time-based access control using permission sets + inline policy conditions (aws:CurrentTime) - Create group/user (e.g., securityAuditors / secAuditUser) and assign permission set to an AWS account - Verify access before/after changing time window 11/21/2025 11/21/2025 https://000012.awsstudygroup.com/3-using-time-based-access-control/ 7 - Implement Customer Managed Policies (CMP) with permission sets (policy name must match across accounts) - Explore Identity Store APIs using Python/Boto3 sample repo (create group/user, add user to group, list members \u0026amp; memberships) - Clean up resources (delete stack if created, remove IAM Identity Center configuration after documenting settings) 11/22/2025 11/22/2025 https://000012.awsstudygroup.com/4-using-customer-managed-policies/ https://000012.awsstudygroup.com/%CC%805-iam-identity-center-identity-store-apis/ https://000012.awsstudygroup.com/6-clean-up/#resource-cleanup Week 12 Achievements: Understood the purpose and benefits of AWS IAM Identity Center for centralized identity management across multiple AWS accounts.\nBuilt foundational knowledge for multi-account governance with AWS Organizations, including:\ncreating member accounts, organizing OUs, accessing member accounts via Switch Role. Successfully configured AWS CLI authentication with IAM Identity Center and understood why automatic credential refresh improves security (short-lived sessions, less exposure of credentials).\nImplemented least-privilege controls using:\ntime-based access control in permission set inline policies (UTC time conditions), Customer Managed Policies (CMPs) reused via permission sets across accounts. Learned how IAM Identity Center can be automated at scale using Identity Store APIs (Python/Boto3), including managing users, groups, and membership auditing.\nCompleted resource cleanup steps to prevent unnecessary charges and remove workshop configurations after practice.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.3-s3-secrets-manager/",
	"title": "Create a secret manager",
	"tags": [],
	"description": "",
	"content": "Using AWS Secrets Manager In this section, you will create secrets manager to store a secret. The secrets manager will store the secrets key from your project like username and password from database, jwt secret key, and vnpay. This will useful to store on AWS and don\u0026rsquo;t need to worry about all secret will publish\nContent Create secret manager "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "\rThis section lists and briefly introduces the blogs you have translated.\nBlog 1 - Enhanced Network Security Control: Flow Management with AWS Network Firewall This blog introduces flow capture and flow flush in AWS Network Firewall—two capabilities that improve visibility and control over stateful network flows. You’ll learn key concepts such as active flows, 5-tuple filtering, and stream exception policy, plus how to run capture/flush operations in the console, validate results using flow logs and CloudTrail, and understand operational constraints like one operation per AZ and distributed execution behavior.\nBlog 2 - Validate recovery readiness with AWS Backup restore testing This blog explains why backups must be tested, not just created, and how AWS Backup restore testing automates restore validation to strengthen disaster recovery (DR), compliance, and cyber resilience. You’ll learn the roles of RTO/RPO, how testing runs in isolated environments, and how a distributed multi-account architecture (workload, vault, and forensics accounts) can produce repeatable validation outcomes and audit-ready evidence through reporting and logs.\nBlog 3 - AWS showcases innovation in media and entertainment with cloud and generative AI at NAB 2025 This blog highlights AWS’s presence at NAB 2025, showcasing how cloud and generative AI are transforming media and entertainment workflows. You’ll explore demos and themes such as live cloud production, interactive audience engagement (D2C + second-screen), emerging monetization formats (for example shoppable and virtual placement), and the use of services like Amazon Nova, Amazon Bedrock, Amazon Q, and AWS Media Services to power modern content creation and delivery.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.4-s3-onprem/",
	"title": "Prepare Environment Configuration",
	"tags": [],
	"description": "",
	"content": "AWS Metropolitano Workshop In this section, you will prepare the entire environment for the Metropolitano system running on AWS. This environment includes real-time data processing services, data storage, backend API, data analytics, and CI/CD pipeline.\nThe goal of this section is to build a complete architecture for operating the Metropolitano train system, including:\nReal-time event streaming — processing passenger count, train status, and ticket transactions Event-driven processing using Amazon SQS and SNS RDS for persistent data storage S3 as a data lake for logs, raw data, and analytical datasets EventBridge for orchestrating events across the system CloudWatch for system monitoring QuickSight for data visualization CodePipeline + CodeBuild + CodeDeploy for automated deployment Metropolitano Architecture Overview The architecture below represents the ticketing system, passenger flow, data streaming, and event processing pipeline:\nWhy Prepare the Environment? The Metropolitano system uses multiple AWS services. Preparing the environment ensures:\nService-to-service connectivity — API Gateway ⇄ Lambda ⇄ RDS ⇄ S3 ⇄ DynamoDB Real-time data pipelines using Kinesis, SQS, SNS, and EventBridge Network infrastructure (VPC) for internal communication without using public internet Analytics readiness using QuickSight and an S3 Data Lake Automated application deployment using CodePipeline What You Will Configure in This Section During the Prepare Environment phase, you will create and configure the following:\nVPC \u0026amp; Networking\nSubnets, Route Tables, Security Groups Private \u0026amp; public networking for EC2, RDS, and Lambda EC2 Instances\nSimulated backend or worker nodes IAM Roles for S3 / DynamoDB / Kinesis access Amazon RDS\nPrimary database for the Metropolitano system Stores ticketing, user, and historical data S3 Data Lake\nraw/ (raw data) analytics/ (processed/analytical data) app-assets/ (frontend static assets) Kinesis Data Stream\nCollects real-time passenger metrics and train status SQS + SNS\nHandles transaction queues Sends delay or incident notifications EventBridge\nRoutes events between API, Lambda, Payment, and Alerts CloudWatch\nLogs, Metrics, Alarms, Dashboards QuickSight\nProvides analytical dashboards for system monitoring CodeBuild + CodeDeploy + CodePipeline\nAutomates backend build → test → deployment After Completing This Section You will have a fully prepared AWS environment ready to deploy the entire Metropolitano application, ensuring:\nReliable data storage Real-time event processing Flexible API integration Automated CI/CD pipeline Powerful analytics system "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/4-eventparticipated/",
	"title": "Events Participated",
	"tags": [],
	"description": "",
	"content": "\rDuring my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event name: GenAI and Data (Gen AI and Data Track – AWS Summit)\nDate \u0026amp; time: 09:00 – 17:30, September 18, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nYour role: Attendee\nBrief description: A full-day track focused on AWS Generative AI and data strategy. The sessions covered building a unified data platform for analytics and AI (data ingestion, cost-optimized storage, processing with services such as AWS Glue/EMR/Redshift, and governance), AWS’s GenAI roadmap (Amazon Bedrock and Amazon Q), the concept of an AI-driven software development lifecycle (AI-DLC), security best practices for GenAI applications, and the growing role of AI Agents in improving organizational productivity.\nOutcomes / value gained:\n• Strengthened understanding of GenAI adoption strategy on AWS (start small, iterate, align with business goals).\n• Learned key components of a unified data platform and why governance/access control is as important as storage and processing.\n• Gained practical ideas for applying AI-DLC to improve productivity (documentation, test generation, code suggestions).\n• Reinforced awareness of multi-layered GenAI security (infrastructure, model access controls, application-level protections).\nEvent 2 Event name: GenAI-powered App-DB Modernization workshop\nDate \u0026amp; time: 09:00, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nYour role: Attendee\nBrief description: A workshop on modernizing applications and databases with a focus on moving from legacy architectures to modern patterns such as microservices and event-driven architecture. The event introduced Domain-Driven Design (DDD) techniques (including event storming, bounded contexts, and context mapping), compared integration patterns (pub/sub, point-to-point, streaming), and discussed how compute models evolve from EC2 to containers and serverless. It also presented AI tooling (Amazon Q Developer and transformation agents) to support and accelerate the software development lifecycle and modernization efforts.\nOutcomes / value gained:\n• Improved ability to reason about modernization using a business-first mindset and shared “ubiquitous language.”\n• Learned how to define service boundaries using bounded contexts and apply event-driven communication to reduce coupling.\n• Understood decision criteria for choosing VMs vs containers vs serverless (functions vs containers).\n• Identified actionable ways to apply the workshop concepts: run event-storming sessions, refactor services around bounded contexts, pilot async messaging, and experiment with Amazon Q Developer to boost development productivity.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Set up the project called Metropolitano Overview The Metropolitano AWS Architecture provides a secure, scalable, and highly available cloud environment for running transportation management workloads. This system leverages multiple AWS services to ensure high performance, strong security controls, fast content delivery, operational monitoring, and continuous deployment. In this workshop, you will learn how the Metropolitano platform is structured on AWS and how different components integrate to deliver a seamless experience for both end-users and internal operators.\nThroughout the lab, you will explore how the system uses core AWS components such as CloudFront, S3, Route 53, EC2, RDS, EventBridge, SQS, SNS, Kinesis, and CodePipeline.\nContent Workshop overview Prerequiste Create a secret manager Prepare enviroment Clean up "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/5-workshop/5.5-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Clean Up Resources 1. Networking \u0026amp; VPC Clean Up 1.1 Delete Route 53 Hosted Zone \u0026amp; Resolver Rules Navigate to Route 53 → Hosted Zones.\nDelete the Private Hosted Zone s3.us-east-1.amazonaws.com.\nGo to Route 53 Resolver → Rules.\nDisassociate the rule myS3Rule from VPC Onprem, then delete it.\n1.2 Delete VPC Resources Steps:\nGo to EC2 → Network Interfaces\nDelete ENIs created for VPC Endpoints, Resolver Endpoints, or EC2 instances after termination. Go to VPC console:\nDelete Security Groups created for the lab. Delete Subnets (ensure no ENIs or route tables attached). Delete Route Tables. Delete Internet Gateway (detach first). Delete NAT Gateway (if created). Finally, delete the VPC metropolitano. 2. EC2 Clean Up Go to EC2 → Instances. Select instance metropolitano-version-1 and Terminate. Delete: Elastic IPs (if allocated) Key pair myKey.pm (local file optional) Security group public-web-sg 3. RDS Clean Up Go to RDS Console → Databases. Select SQL Server instance and choose Delete. Options: Disable final snapshot (optional) Delete the DB Subnet Group private-db-metropolitano. Delete the security group private-db-sg if unused. 4. S3 Clean Up Go to S3 Console. Empty the bucket metropolitano-2025. Click Delete bucket. 5. CloudFront Clean Up Go to CloudFront → Distributions. Select the distribution. Choose Disable → Wait for status “Disabled”. Click Delete. 6. Kinesis Data Stream Clean Up Go to Kinesis Console → Data Streams. Select metropolitano-stream. Click Delete. 7. EventBridge Clean Up Go to EventBridge → Rules. Select metropolitano-event-rule. Click Delete. If event buses or targets were created manually, delete them too. 8. SQS Queue Clean Up Go to SQS Console → Queues. Select metropolitano-queue. Click Delete. 9. SNS Clean Up Go to SNS Console → Topics. Select metropolitano-alerts. Delete subscriptions (email/SMS). Delete topic. 10. CloudWatch Clean Up 10.1 Delete Alarms CloudWatch → Alarms → Select alarms → Delete. 10.2 Delete Logs CloudWatch → Log Groups Delete: EC2 log groups Lambda log groups (if any) VPC Flow Logs (if created) 10.3 Delete Metrics (optional) Metrics automatically expire; no action required.\n11. QuickSight Clean Up If enabled, QuickSight can generate monthly cost.\nSteps:\nGo to QuickSight Console → Manage QuickSight.\nDelete:\nDatasets SPICE datasets Dashboards Analyses If not needed → Unsubscribe QuickSight account.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "\rDuring my internship at Amazon Web Services (AWS) from 08/09 to 24/12, I had the opportunity to learn, practice, and apply the knowledge I gained at school in a real working environment.\nI participated in the Metro project, through which I improved skills such as programming, requirements analysis, reading and understanding documentation, report writing, and communication in a professional environment.\nIn terms of work ethic, I always tried to complete tasks well, complied with company regulations, and actively communicated with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ␐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ☐ ✅ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, improvement initiatives, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking: analyze root causes, propose solution approaches, and learn from each execution Learn to communicate better in daily interactions and at work, especially situational handling and clear communication "
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": "\rOveral Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions (My Answers) What did you find most satisfying during your internship?\nI was most satisfied with the supportive environment and the mentoring approach that encouraged me to learn by doing. My mentor consistently guided me with clear explanations and constructive feedback, while still giving me space to explore solutions independently. This helped me build confidence and improve my problem-solving ability.\nWhat do you think the company should improve for future interns?\nI think the experience could be improved by:\nProviding a clearer week-by-week onboarding roadmap (tools, documents, and expected learning milestones). Adding more short sharing sessions on practical topics (best practices, reporting, communication, real project case studies). Organizing more team bonding/networking activities to help interns connect with members across teams and feel even more integrated. If recommending to a friend, would you suggest they intern here? Why or why not?\nYes, I would recommend it. The internship offers a professional working environment, meaningful learning opportunities, and strong mentorship. Interns are treated with respect and are encouraged to grow through real tasks, feedback, and collaboration.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience?\nMy suggestions are:\nCreate a centralized Intern Handbook/Notion page with key processes, FAQs, and writing guidelines for updates/reports. Hold a short weekly sync between interns and mentors/admins to quickly surface blockers and align expectations. Add a mini demo/checkpoint at the end of each phase so interns can present progress and receive early feedback. Would you like to continue this program in the future?\nYes. If possible, I would like to continue as an advanced intern or contribute by supporting/mentoring future interns, because I found the program valuable and clearly beneficial for my growth.\nAny other comments (free sharing):\nThank you to the FCJ team, mentors, and admins for the support throughout the internship. I truly appreciate the professional yet approachable culture. I hope the program continues to expand and becomes even more impactful for future cohorts.\n"
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://TranVanQuyet04.github.io/FJC-report/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]